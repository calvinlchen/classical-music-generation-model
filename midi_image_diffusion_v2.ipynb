{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea2c451b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'd:\\\\classical-music-generation-model\\\\models.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data_preprocessing, midi_conversion, model_helpers, models\n",
    "\n",
    "importlib.reload(data_preprocessing)\n",
    "importlib.reload(midi_conversion)\n",
    "importlib.reload(model_helpers)\n",
    "importlib.reload(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c609bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading MIDIs from data\\train.\n",
      "Could not load data\\train\\mozart-piano_sonatas-nueva_carpeta-k281_piano_sonata_n03_3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Could not load data\\train\\unknown_artist-i_o-mozart_k550.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 311 MIDI files from data\\train\n",
      "Now loading MIDIs from data\\val.\n",
      "Loaded 29 MIDI files from data\\val\n",
      "Now loading MIDIs from data\\test.\n",
      "Could not load data\\test\\unknown_artist-i_o-mozart_q1_2.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 28 MIDI files from data\\test\n",
      "368 MIDI files retrieved.\n",
      "Successfully processed 311 MIDIs into 13994 images.\n",
      "Successfully processed 29 MIDIs into 1336 images.\n",
      "Successfully processed 28 MIDIs into 1305 images.\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_midis_by_composer, process_midis_to_images\n",
    "import os\n",
    "\n",
    "composers = [\"mozart\", \"haydn\"]\n",
    "midis = get_midis_by_composer(composers)\n",
    "\n",
    "train_midis, val_midis, test_midis = midis\n",
    "\n",
    "# Extract just the MidiFile objects (not composer strings)\n",
    "train_midi_objs = [m for (m, c) in train_midis]\n",
    "\n",
    "# Convert all train MIDIs to images\n",
    "train_images = process_midis_to_images(train_midi_objs)\n",
    "\n",
    "# Save the images\n",
    "output_path = \"generated/train_images_taller\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for i, img in enumerate(train_images):\n",
    "    img.save(os.path.join(output_path, f\"train_window_{i:03d}.png\"))\n",
    "\n",
    "# Repeat process for validation and testing images\n",
    "val_midi_objs = [m for (m, c) in val_midis]\n",
    "val_images = process_midis_to_images(val_midi_objs)\n",
    "output_path = \"generated/val_images_taller\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for i, img in enumerate(val_images):\n",
    "    img.save(os.path.join(output_path, f\"val_window_{i:03d}.png\"))\n",
    "\n",
    "test_midi_objs = [m for (m, c) in test_midis]\n",
    "test_images = process_midis_to_images(test_midi_objs)\n",
    "output_path = \"generated/test_images_taller\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for i, img in enumerate(test_images):\n",
    "    img.save(os.path.join(output_path, f\"test_window_{i:03d}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cd9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13994 images in generated/train_images_taller\n",
      "Found 1336 images in generated/val_images_taller\n",
      "Reduced to 12000 random images.\n",
      "cuda\n",
      "\n",
      "Training for 200 epochs. Validation & checkpoint every 10 epochs.\n",
      "Early Stopping Patience: 5 checks (≈50 epochs).\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Block 1/20:  70%|███████   | 7/10 [02:52<01:13, 24.39s/it, loss=0.0423]"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import PianoRollDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from models import SimpleUNet, train_diffusion_with_early_stopping\n",
    "import torch\n",
    "\n",
    "# TRAINING ON 12,000 IMAGES (rather than 1,000)\n",
    "\n",
    "train_dataset = PianoRollDataset(\"generated/train_images_taller\")\n",
    "val_dataset = PianoRollDataset(\"generated/val_images_taller\")\n",
    "\n",
    "N = 12000\n",
    "perm_train = torch.randperm(len(train_dataset))[:N]\n",
    "subset_train = Subset(train_dataset, perm_train.tolist())\n",
    "print(f\"Reduced to {len(subset_train)} random images.\")\n",
    "\n",
    "train_loader = DataLoader(subset_train, batch_size=24, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=24, shuffle=False)\n",
    "\n",
    "T = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = SimpleUNet().to(device)\n",
    "\n",
    "losses = train_diffusion_with_early_stopping(model, train_loader, val_loader, T, num_epochs=200, lr=1e-4, gen_freq=10,\n",
    "                                             device=device, save_dir=\"models\\diffusion_12000\", weight_decay=1e-4, patience=5,\n",
    "                                             save_checkpoints=True, alpha_start=0.6, alpha_end=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
