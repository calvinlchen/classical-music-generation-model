{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da623df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'text_processing' from 'd:\\\\classical-music-generation-model\\\\text_processing.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import importlib\n",
    "import data_preprocessing, midi_conversion, model_helpers, models, text_processing\n",
    "\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Config\n",
    ")\n",
    "\n",
    "importlib.reload(data_preprocessing)\n",
    "importlib.reload(midi_conversion)\n",
    "importlib.reload(model_helpers)\n",
    "importlib.reload(models)\n",
    "importlib.reload(text_processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafd936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "DATA_DIR = \"data/midi_text_exports\"\n",
    "VOCAB_FILE = \"data/midi_text_exports/midi_vocab.txt\"\n",
    "BLOCK_SIZE = 512\n",
    "BATCH_SIZE = 24\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "MODEL_SAVE_DIR = \"models/midi_gpt2_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6931e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading MIDIs from data\\train.\n",
      "Could not load data\\train\\beethoven-anhang_14_3.mid: Could not decode key with 3 flats and mode 255\n",
      "Could not load data\\train\\mozart-piano_sonatas-nueva_carpeta-k281_piano_sonata_n03_3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Could not load data\\train\\unknown_artist-i_o-mozart_k550.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 500 MIDI files from data\\train\n",
      "Now loading MIDIs from data\\val.\n",
      "Loaded 47 MIDI files from data\\val\n",
      "Now loading MIDIs from data\\test.\n",
      "Could not load data\\test\\unknown_artist-i_o-mozart_q1_2.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 43 MIDI files from data\\test\n",
      "590 MIDI files retrieved.\n",
      "Successfully processed 500 MIDIs into text.\n",
      "Successfully processed 47 MIDIs into text.\n",
      "Successfully processed 43 MIDIs into text.\n",
      "Saved 500 files to                       data/midi_text_exports\\train\n",
      "Saved 47 files to                       data/midi_text_exports\\val\n",
      "Saved 43 files to                       data/midi_text_exports\\test\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_midis_by_composer, midi_split_to_text_split\n",
    "\n",
    "composers = [\"mozart\", \"haydn\", \"beethoven\"]\n",
    "midis = get_midis_by_composer(composers)\n",
    "\n",
    "# [[train texts], [val texts], [test texts]]\n",
    "# Export dir: \"data/midi_text_exports\"\n",
    "midi_texts = midi_split_to_text_split(midis, save_to_directory=\"data/midi_text_exports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34d8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing vocab file: data/midi_text_exports/midi_vocab.txt\n",
      "MIDI vocab size: 701\n"
     ]
    }
   ],
   "source": [
    "from text_processing import build_vocab_from_dir\n",
    "from text_processing import MidiTokenizer\n",
    "\n",
    "\n",
    "if not os.path.exists(VOCAB_FILE):\n",
    "    print(f\"{VOCAB_FILE} not found, building from {DATA_DIR}...\")\n",
    "    counter = build_vocab_from_dir(DATA_DIR)\n",
    "    base_tokens = sorted(counter.keys())\n",
    "    specials = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"]\n",
    "    vocab = specials + base_tokens\n",
    "    with open(VOCAB_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        for tok in vocab:\n",
    "            f.write(tok + \"\\n\")\n",
    "    print(f\"Saved vocab with {len(vocab)} tokens to {VOCAB_FILE}\")\n",
    "else:\n",
    "    print(f\"Found existing vocab file: {VOCAB_FILE}\")\n",
    "\n",
    "tokenizer = MidiTokenizer(VOCAB_FILE)\n",
    "vocab_size = len(tokenizer.get_vocab())\n",
    "print(\"MIDI vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9acefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21696 sequences from data/midi_text_exports\\train\n",
      "Loaded 1962 sequences from data/midi_text_exports\\val\n"
     ]
    }
   ],
   "source": [
    "from text_processing import MidiTextDataset\n",
    "from model_helpers import collate_fn\n",
    "\n",
    "\n",
    "train_dataset = MidiTextDataset(os.path.join(DATA_DIR, \"train\"), tokenizer, block_size=BLOCK_SIZE)\n",
    "val_dataset   = MidiTextDataset(os.path.join(DATA_DIR, \"val\"),   tokenizer, block_size=BLOCK_SIZE)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained GPT-2...\n",
      "GPT-2 hidden size: 768\n",
      "Model ready. New vocab size: 701\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pretrained GPT-2...\")\n",
    "base_model_name = \"gpt2\"  # you can try \"gpt2-medium\" if you have VRAM\n",
    "\n",
    "pretrained_model = GPT2LMHeadModel.from_pretrained(base_model_name)\n",
    "base_config = pretrained_model.config\n",
    "\n",
    "hidden_size = base_config.n_embd\n",
    "print(\"GPT-2 hidden size:\", hidden_size)\n",
    "\n",
    "# New config: same architecture, new vocab size + pad/bos/eos\n",
    "new_config = GPT2Config(\n",
    "    vocab_size=vocab_size,\n",
    "    n_positions=base_config.n_positions,\n",
    "    n_ctx=base_config.n_ctx,\n",
    "    n_embd=base_config.n_embd,\n",
    "    n_layer=base_config.n_layer,\n",
    "    n_head=base_config.n_head,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    resid_pdrop=0.2,  # for mitigating overfitting\n",
    "    embd_pdrop=0.2,\n",
    "    attn_pdrop=0.2,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(new_config)\n",
    "\n",
    "# Copy transformer blocks and positional embeddings from pretrained\n",
    "with torch.no_grad():\n",
    "    # positional embeddings\n",
    "    model.transformer.wpe.weight.copy_(pretrained_model.transformer.wpe.weight)\n",
    "\n",
    "    # transformer blocks\n",
    "    for new_block, old_block in zip(model.transformer.h, pretrained_model.transformer.h):\n",
    "        new_block.load_state_dict(old_block.state_dict())\n",
    "\n",
    "    # final layer norm\n",
    "    model.transformer.ln_f.load_state_dict(pretrained_model.transformer.ln_f.state_dict())\n",
    "\n",
    "    # We intentionally leave token embeddings (wte) and lm_head randomly initialized\n",
    "    # to match new vocab.\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "print(\"Model ready. New vocab size:\", model.config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a06d67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 904/904 [09:51<00:00,  1.53it/s, batch_loss=1.0457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | train loss:               2.6200 | val loss: 1.1237\n",
      "  -> saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 904/904 [09:43<00:00,  1.55it/s, batch_loss=0.9353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | train loss:               0.9596 | val loss: 0.9537\n",
      "  -> saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.7254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | train loss:               0.8253 | val loss: 0.8794\n",
      "  -> saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.8048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | train loss:               0.7546 | val loss: 0.8527\n",
      "  -> saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 904/904 [09:43<00:00,  1.55it/s, batch_loss=0.8338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | train loss:               0.7061 | val loss: 0.8355\n",
      "  -> saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.6464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | train loss:               0.6669 | val loss: 0.8307\n",
      "  -> saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.6638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | train loss:               0.6322 | val loss: 0.8278\n",
      "  -> saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 904/904 [09:45<00:00,  1.54it/s, batch_loss=0.6333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | train loss:               0.5998 | val loss: 0.8327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.6043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | train loss:               0.5697 | val loss: 0.8399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.6018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | train loss:               0.5413 | val loss: 0.8548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.4291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | train loss:               0.5149 | val loss: 0.8657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 904/904 [09:45<00:00,  1.54it/s, batch_loss=0.4671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | train loss:               0.4902 | val loss: 0.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 904/904 [09:43<00:00,  1.55it/s, batch_loss=0.4583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | train loss:               0.4675 | val loss: 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 904/904 [09:43<00:00,  1.55it/s, batch_loss=0.4454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | train loss:               0.4466 | val loss: 0.9109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 904/904 [10:00<00:00,  1.51it/s, batch_loss=0.6344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | train loss:               0.4278 | val loss: 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 904/904 [09:59<00:00,  1.51it/s, batch_loss=0.4723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | train loss:               0.4108 | val loss: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 904/904 [09:45<00:00,  1.54it/s, batch_loss=0.5193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | train loss:               0.3961 | val loss: 0.9587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 904/904 [09:45<00:00,  1.54it/s, batch_loss=0.4008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | train loss:               0.3831 | val loss: 0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 904/904 [09:44<00:00,  1.55it/s, batch_loss=0.3547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | train loss:               0.3729 | val loss: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 904/904 [09:50<00:00,  1.53it/s, batch_loss=0.3447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | train loss:               0.3648 | val loss: 0.9856\n"
     ]
    }
   ],
   "source": [
    "from models import train_gpt_2\n",
    "\n",
    "train_gpt_2(model, train_loader, val_loader, num_epochs=NUM_EPOCHS, lr=LEARNING_RATE,\n",
    "            weight_decay=WEIGHT_DECAY, device=DEVICE, model_save_dir=MODEL_SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "945e2ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token sequence:\n",
      "<SOS> COMPOSER_haydn KEY_F TIME_SIGNATURE_3/4 TEMPO_BPM_50 MEASURE BEAT POS_0 NOTE_39 DUR_44 VEL_4 N ...\n",
      "Saved generated MIDI to: generated\\gpt2_generated_sample.mid\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "from midi_conversion import text_to_midi\n",
    "import torch, os\n",
    "\n",
    "def generate_midi_tokens(\n",
    "    prompt_text: str,\n",
    "    max_new_tokens: int = 256,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = 50,\n",
    "):\n",
    "    tok = MidiTokenizer(VOCAB_FILE)\n",
    "    mdl = GPT2LMHeadModel.from_pretrained(MODEL_SAVE_DIR).to(DEVICE)\n",
    "    mdl.eval()\n",
    "\n",
    "    prompt_ids = tok.encode(prompt_text, add_special_tokens=False)\n",
    "\n",
    "    # Build input: [BOS] + prompt tokens  (no EOS)\n",
    "    input_ids = torch.tensor([[tok.bos_token_id] + prompt_ids], dtype=torch.long).to(DEVICE)\n",
    "    attention_mask = (input_ids != tok.pad_token_id).long()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = mdl.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            pad_token_id=tok.pad_token_id,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "        )\n",
    "\n",
    "    generated_ids = output_ids[0].tolist()\n",
    "    generated_text = tok.decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Example prompt\n",
    "example_prompt = \"\"\n",
    "generated_tokens = generate_midi_tokens(example_prompt, max_new_tokens=1024)\n",
    "print(\"Generated token sequence:\")\n",
    "print(generated_tokens[:100], \"...\" if len(generated_tokens) > 500 else \"\")\n",
    "\n",
    "# Convert generated text to MIDI and save\n",
    "generated_mid = text_to_midi(generated_tokens)\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "midi_path = os.path.join(\"generated\", \"gpt2_generated_sample.mid\")\n",
    "generated_mid.save(midi_path)\n",
    "print(\"Saved generated MIDI to:\", midi_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
