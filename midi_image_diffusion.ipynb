{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7610b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'c:\\\\Users\\\\racer\\\\OneDrive - Duke University\\\\CS372\\\\project_clone\\\\classical-music-generation-model\\\\models.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data_preprocessing, midi_conversion, model_helpers, models\n",
    "\n",
    "importlib.reload(data_preprocessing)\n",
    "importlib.reload(midi_conversion)\n",
    "importlib.reload(model_helpers)\n",
    "importlib.reload(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99932a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading MIDIs from data\\train.\n",
      "Could not load data\\train\\mozart-piano_sonatas-nueva_carpeta-k281_piano_sonata_n03_3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Could not load data\\train\\unknown_artist-i_o-mozart_k550.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 311 MIDI files from data\\train\n",
      "Now loading MIDIs from data\\val.\n",
      "Loaded 29 MIDI files from data\\val\n",
      "Now loading MIDIs from data\\test.\n",
      "Could not load data\\test\\unknown_artist-i_o-mozart_q1_2.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 28 MIDI files from data\\test\n",
      "368 MIDI files retrieved.\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_midis_by_composer\n",
    "\n",
    "composers = [\"mozart\", \"haydn\"]\n",
    "midis = get_midis_by_composer(composers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a738eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 311 MIDIs into 3605 images.\n",
      "Successfully processed 29 MIDIs into 345 images.\n",
      "Successfully processed 28 MIDIs into 336 images.\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import process_midis_to_images\n",
    "import os\n",
    "\n",
    "train_midis, val_midis, test_midis = midis\n",
    "\n",
    "# Extract just the MidiFile objects (not composer strings)\n",
    "train_midi_objs = [m for (m, c) in train_midis]\n",
    "\n",
    "# Convert all train MIDIs to images\n",
    "train_images = process_midis_to_images(train_midi_objs)\n",
    "\n",
    "# Save the images\n",
    "output_path = \"generated/train_images\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for i, img in enumerate(train_images):\n",
    "    img.save(os.path.join(output_path, f\"train_window_{i:03d}.png\"))\n",
    "\n",
    "# Repeat process for validation and testing images\n",
    "val_midi_objs = [m for (m, c) in val_midis]\n",
    "val_images = process_midis_to_images(val_midi_objs)\n",
    "output_path = \"generated/val_images\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for i, img in enumerate(val_images):\n",
    "    img.save(os.path.join(output_path, f\"val_window_{i:03d}.png\"))\n",
    "\n",
    "test_midi_objs = [m for (m, c) in test_midis]\n",
    "test_images = process_midis_to_images(test_midi_objs)\n",
    "output_path = \"generated/test_images\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for i, img in enumerate(test_images):\n",
    "    img.save(os.path.join(output_path, f\"test_window_{i:03d}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "417c5d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3605 images in generated/train_images\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import PianoRollDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = PianoRollDataset(\"generated/train_images\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c164524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3605 images in generated/train_images\n",
      "\n",
      "Generating example every 20 epochs.\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Group 1/10:  10%|â–ˆ         | 2/20 [02:08<19:15, 64.21s/it, loss=0.1013]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models import SimpleUNet, train_diffusion_model\n",
    "\n",
    "T = 200\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = PianoRollDataset(\"generated/train_images\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "model = SimpleUNet().to(device)  # or with smaller channels\n",
    "\n",
    "losses = train_diffusion_model(model, train_loader, T, num_epochs=200, lr=1e-4, gen_freq=20, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb13013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import sample_image\n",
    "from model_helpers import prepare_noise_schedule, show_image_tensor\n",
    "\n",
    "_, alphas = prepare_noise_schedule(device, timesteps=T)\n",
    "sample = sample_image(model, alphas, device)     # [1,88,1024]\n",
    "show_image_tensor(sample, title=\"Generated piano roll\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61622f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi_conversion import pianoroll_images_to_midi\n",
    "import numpy as np\n",
    "\n",
    "sample_01 = (sample + 1.0) / 2.0\n",
    "sample_01 = sample_01.squeeze(0).cpu().numpy()   # [88, 1024] in [0,1]\n",
    "sample_img = (sample_01 * 255).astype(np.uint8)\n",
    "img = Image.fromarray(sample_img, mode=\"L\")\n",
    "\n",
    "mid = pianoroll_images_to_midi([img], tempo_bpm=120, time_signature=(4, 4))\n",
    "mid.save(\"generated_diffusion_piece.mid\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
