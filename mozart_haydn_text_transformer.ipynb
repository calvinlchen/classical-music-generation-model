{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1701307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading MIDIs from data\\train.\n",
      "Could not load data\\train\\mozart-piano_sonatas-nueva_carpeta-k281_piano_sonata_n03_3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Could not load data\\train\\unknown_artist-i_o-mozart_k550.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 311 MIDI files from data\\train\n",
      "Now loading MIDIs from data\\val.\n",
      "Loaded 29 MIDI files from data\\val\n",
      "Now loading MIDIs from data\\test.\n",
      "Could not load data\\test\\unknown_artist-i_o-mozart_q1_2.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 28 MIDI files from data\\test\n",
      "368 MIDI files retrieved.\n",
      "Successfully processed 311 MIDIs into text.\n",
      "Successfully processed 29 MIDIs into text.\n",
      "Successfully processed 28 MIDIs into text.\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_midis_by_composer, process_midis_to_text\n",
    "\n",
    "composers = [\"mozart\", \"haydn\"]\n",
    "midis = get_midis_by_composer(composers)\n",
    "\n",
    "# [[train texts], [val texts], [test texts]]\n",
    "midi_texts = [[],[],[]]\n",
    "\n",
    "for i in range(len(midis)):\n",
    "    midi_texts[i] = process_midis_to_text(midis[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ec6c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (train only): 627\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import VocabBuilder\n",
    "import torch\n",
    "\n",
    "# Training sequences\n",
    "training_texts = midi_texts[0]\n",
    "\n",
    "# Build vocab from training data\n",
    "vb = VocabBuilder(training_texts)\n",
    "train_ids = vb. train_ids\n",
    "\n",
    "# Encode validation and testing data texts\n",
    "val_ids = torch.tensor([tok for seq in midi_texts[1] for tok in vb.encode(seq)], dtype=torch.long)\n",
    "test_ids = torch.tensor([tok for seq in midi_texts[2] for tok in vb.encode(seq)], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a22ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 5.663, acc 0.075 | val loss 5.738, acc 0.073\n",
      "step 500: train loss 1.514, acc 0.577 | val loss 1.714, acc 0.542\n",
      "step 1000: train loss 1.329, acc 0.619 | val loss 1.575, acc 0.566\n",
      "step 1500: train loss 1.246, acc 0.645 | val loss 1.487, acc 0.591\n",
      "step 2000: train loss 1.206, acc 0.653 | val loss 1.438, acc 0.612\n",
      "step 2500: train loss 1.136, acc 0.672 | val loss 1.435, acc 0.610\n",
      "step 3000: train loss 1.075, acc 0.684 | val loss 1.437, acc 0.608\n",
      "step 3500: train loss 1.074, acc 0.687 | val loss 1.339, acc 0.635\n",
      "step 4000: train loss 1.087, acc 0.689 | val loss 1.310, acc 0.640\n",
      "step 4500: train loss 1.047, acc 0.698 | val loss 1.315, acc 0.641\n",
      "step 5000: train loss 1.077, acc 0.688 | val loss 1.282, acc 0.650\n",
      "step 5500: train loss 0.960, acc 0.720 | val loss 1.324, acc 0.639\n",
      "step 6000: train loss 0.984, acc 0.714 | val loss 1.340, acc 0.638\n",
      "step 6500: train loss 0.960, acc 0.720 | val loss 1.282, acc 0.656\n",
      "step 7000: train loss 0.927, acc 0.730 | val loss 1.293, acc 0.652\n",
      "step 7500: train loss 0.982, acc 0.713 | val loss 1.306, acc 0.654\n",
      "step 8000: train loss 0.917, acc 0.731 | val loss 1.303, acc 0.651\n",
      "step 8500: train loss 0.910, acc 0.734 | val loss 1.301, acc 0.652\n",
      "step 9000: train loss 0.936, acc 0.726 | val loss 1.291, acc 0.657\n",
      "step 9500: train loss 0.924, acc 0.732 | val loss 1.255, acc 0.660\n"
     ]
    }
   ],
   "source": [
    "from models import MidiTextTransformer, train_midi_text_transformer, generate_midi_tokens_with_transformer\n",
    "from data_preprocessing import SEQ_SOS, SEQ_EOS\n",
    "\n",
    "vocab_size = vb.vocab_size\n",
    "\n",
    "model = MidiTextTransformer(vocab_size=vocab_size, d_model=512, n_head=8, n_layer=8,\n",
    "                          dim_ff=1024, block_size=1024)\n",
    "\n",
    "trained_model = train_midi_text_transformer(\n",
    "    model,\n",
    "    train_ids=train_ids,\n",
    "    val_ids=val_ids,\n",
    "    vocab_size=vocab_size,\n",
    "    max_iters=10000,\n",
    "    eval_interval=500,\n",
    "    lr=3e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd9dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 chars of generated text:\n",
      "\n",
      "<SOS> COMPOSER_haydn KEY_F TIME_SIGNATURE_4/4 TEMPO_BPM_90 MEASURE BEAT POS_0 NOTE_41 DUR_22 VEL_5 N\n"
     ]
    }
   ],
   "source": [
    "# IDs for special tokens\n",
    "SOS_ID = vb.stoi[SEQ_SOS]\n",
    "EOS_ID = vb.stoi[SEQ_EOS]\n",
    "\n",
    "# Seed with first few tokens from the first piece in the testing set\n",
    "seed_tokens = vb.encode(midi_texts[2][0])[:300]\n",
    "\n",
    "generated_ids = generate_midi_tokens_with_transformer(\n",
    "    model,\n",
    "    sos_id=SOS_ID,\n",
    "    eos_id=EOS_ID,\n",
    "    start_tokens=seed_tokens,\n",
    "    max_new_tokens=2000,\n",
    ")\n",
    "\n",
    "generated_text = vb.decode(generated_ids)\n",
    "\n",
    "print(\"First 100 chars of generated text:\\n\")\n",
    "print(generated_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5000eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi_conversion import text_to_midi\n",
    "import os\n",
    "\n",
    "mid = text_to_midi(generated_text)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "\n",
    "# Save to path\n",
    "output_path = os.path.join(\"generated\", \"mozart_output_on_expanded_training_data.mid\")\n",
    "mid.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8827a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Saving the model\n",
    "\n",
    "torch.save(model.state_dict(), \"models/transformer_weights.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
