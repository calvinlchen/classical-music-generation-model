{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b5b947-7907-4c08-b8ce-ae09470e3e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load data\\train\\mozart-piano_sonatas-nueva_carpeta-k281_piano_sonata_n03_3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Could not load data\\train\\unknown_artist-i_o-mozart_k550.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 231 Mozart MIDI files from train/\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import mido\n",
    "\n",
    "train_path = Path(\"data/train\")\n",
    "\n",
    "# Collect all Mozart MIDI files\n",
    "mozart_midis = []\n",
    "for midi_file in train_path.glob(\"*.mid\"):\n",
    "    if \"mozart\" in midi_file.name.lower():\n",
    "        try:\n",
    "            midi_obj = mido.MidiFile(midi_file)\n",
    "            mozart_midis.append(midi_obj)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load {midi_file}: {e}\")\n",
    "\n",
    "print(f\"Loaded {len(mozart_midis)} Mozart MIDI files from train/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "092114be-7989-435b-9beb-a254e60d0630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozart text processing completed.\n"
     ]
    }
   ],
   "source": [
    "from midi_conversion import midi_to_text\n",
    "import importlib\n",
    "\n",
    "importlib.reload(midi_conversion)\n",
    "\n",
    "mozart_texts = []\n",
    "\n",
    "# print(midi_to_text(mozart_midis[0]))\n",
    "\n",
    "total = len(mozart_midis)\n",
    "for i, mid in enumerate(mozart_midis, start=1):\n",
    "    mozart_texts.append(midi_to_text(mid, \"mozart\"))\n",
    "    print(f\"Processed {i}/{total} files\", end=\"\\r\")\n",
    "\n",
    "SEQ_SOS = \"<SOS>\"\n",
    "SEQ_EOS = \"<EOS>\"\n",
    "seqs = [f\"{SEQ_SOS} {txt} {SEQ_EOS}\" for txt in mozart_texts]\n",
    "\n",
    "print(\"Mozart text processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c416325c-81f3-4d43-ad0c-106768c5ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 1114\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch, math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1) tokenize: your format is already space-separated\n",
    "all_tokens = []\n",
    "for s in seqs:\n",
    "    all_tokens.extend(s.split())\n",
    "\n",
    "vocab = sorted(set(all_tokens))\n",
    "stoi = {t:i for i, t in enumerate(vocab)}\n",
    "itos = {i:t for t,i in stoi.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "def encode(text: str):\n",
    "    return [stoi[t] for t in text.split()]\n",
    "\n",
    "def decode(ids):\n",
    "    return \" \".join(itos[int(i)] for i in ids)\n",
    "\n",
    "# concatenate all pieces into one long stream\n",
    "ids = torch.tensor([stoi[t] for t in all_tokens], dtype=torch.long)\n",
    "\n",
    "# train/val split\n",
    "n = int(0.9 * len(ids))\n",
    "train_data = ids[:n]\n",
    "val_data   = ids[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8a8475d-c157-41ad-8844-c486bbad018b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "block_size = 128   # sequence length\n",
    "batch_size = 32\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(0, len(data) - block_size - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size]     for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "473eca60-9c72-454d-8cf9-9e05f7a0e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozartTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256,\n",
    "                 n_head=4, n_layer=6, dim_ff=512, block_size=512):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding(block_size, d_model)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_head,\n",
    "            dim_feedforward=dim_ff,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=n_layer)\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        assert T <= self.block_size\n",
    "        pos = torch.arange(T, device=x.device).unsqueeze(0).expand(B, T)\n",
    "        h = self.tok_emb(x) + self.pos_emb(pos)\n",
    "\n",
    "        # causal mask: prevent attention to future positions\n",
    "        mask = torch.triu(torch.ones(T, T, device=x.device) * float(\"-inf\"), diagonal=1)\n",
    "        h = self.encoder(h, mask)\n",
    "        logits = self.lm_head(h)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99e2c01f-a4f5-4bad-8594-98c4468a5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MozartTransformer(vocab_size, block_size=block_size).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba23a8cb-4a61-409f-b3e7-67f38d00b08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.636, acc 0.577 | val loss 1.729, acc 0.554\n",
      "step 250: train loss 1.786, acc 0.540 | val loss 1.686, acc 0.560\n",
      "step 500: train loss 1.700, acc 0.557 | val loss 1.681, acc 0.565\n",
      "step 750: train loss 1.640, acc 0.575 | val loss 1.741, acc 0.555\n",
      "step 1000: train loss 1.682, acc 0.564 | val loss 1.741, acc 0.553\n",
      "step 1250: train loss 1.666, acc 0.572 | val loss 1.665, acc 0.567\n",
      "step 1500: train loss 1.600, acc 0.591 | val loss 1.749, acc 0.550\n",
      "step 1750: train loss 1.576, acc 0.587 | val loss 1.685, acc 0.564\n",
      "step 2000: train loss 1.735, acc 0.553 | val loss 1.702, acc 0.559\n",
      "step 2250: train loss 1.660, acc 0.573 | val loss 1.660, acc 0.566\n",
      "step 2500: train loss 1.599, acc 0.582 | val loss 1.728, acc 0.559\n",
      "step 2750: train loss 1.498, acc 0.609 | val loss 1.689, acc 0.562\n",
      "step 3000: train loss 1.590, acc 0.590 | val loss 1.716, acc 0.558\n",
      "step 3250: train loss 1.548, acc 0.597 | val loss 1.698, acc 0.565\n",
      "step 3500: train loss 1.546, acc 0.600 | val loss 1.708, acc 0.562\n",
      "step 3750: train loss 1.623, acc 0.578 | val loss 1.639, acc 0.575\n",
      "step 4000: train loss 1.579, acc 0.586 | val loss 1.667, acc 0.569\n",
      "step 4250: train loss 1.494, acc 0.610 | val loss 1.665, acc 0.572\n",
      "step 4500: train loss 1.583, acc 0.590 | val loss 1.688, acc 0.563\n",
      "step 4750: train loss 1.550, acc 0.591 | val loss 1.642, acc 0.576\n",
      "step 5000: train loss 1.519, acc 0.602 | val loss 1.600, acc 0.586\n",
      "step 5250: train loss 1.485, acc 0.611 | val loss 1.704, acc 0.570\n",
      "step 5500: train loss 1.526, acc 0.603 | val loss 1.691, acc 0.562\n",
      "step 5750: train loss 1.579, acc 0.587 | val loss 1.653, acc 0.573\n",
      "step 6000: train loss 1.471, acc 0.610 | val loss 1.675, acc 0.568\n",
      "step 6250: train loss 1.538, acc 0.597 | val loss 1.630, acc 0.576\n",
      "step 6500: train loss 1.568, acc 0.594 | val loss 1.664, acc 0.576\n",
      "step 6750: train loss 1.510, acc 0.602 | val loss 1.734, acc 0.556\n",
      "step 7000: train loss 1.494, acc 0.607 | val loss 1.675, acc 0.572\n",
      "step 7250: train loss 1.486, acc 0.609 | val loss 1.675, acc 0.572\n",
      "step 7500: train loss 1.588, acc 0.588 | val loss 1.692, acc 0.568\n",
      "step 7750: train loss 1.505, acc 0.605 | val loss 1.679, acc 0.569\n",
      "step 8000: train loss 1.512, acc 0.605 | val loss 1.620, acc 0.580\n",
      "step 8250: train loss 1.459, acc 0.617 | val loss 1.586, acc 0.591\n",
      "step 8500: train loss 1.531, acc 0.601 | val loss 1.665, acc 0.576\n",
      "step 8750: train loss 1.459, acc 0.615 | val loss 1.667, acc 0.579\n",
      "step 9000: train loss 1.472, acc 0.614 | val loss 1.612, acc 0.585\n",
      "step 9250: train loss 1.495, acc 0.606 | val loss 1.694, acc 0.570\n",
      "step 9500: train loss 1.391, acc 0.632 | val loss 1.641, acc 0.578\n",
      "step 9750: train loss 1.401, acc 0.632 | val loss 1.625, acc 0.579\n"
     ]
    }
   ],
   "source": [
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    out = {}\n",
    "    with torch.no_grad():\n",
    "        for split in [\"train\", \"val\"]:\n",
    "            losses = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for _ in range(10):\n",
    "                xb, yb = get_batch(split)\n",
    "                logits = model(xb)\n",
    "                loss = F.cross_entropy(\n",
    "                    logits.view(-1, vocab_size),\n",
    "                    yb.view(-1)\n",
    "                )\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # Accuracy\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                correct += (preds == yb).float().sum().item()\n",
    "                total += yb.numel()\n",
    "                \n",
    "            avg_loss = sum(losses) / len(losses)\n",
    "            accuracy = correct / total\n",
    "            out[split] = (avg_loss, accuracy)\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "max_iters = 10000\n",
    "eval_interval = 250\n",
    "\n",
    "for step in range(max_iters):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits = model(xb)\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, vocab_size),\n",
    "        yb.view(-1)\n",
    "    )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        train_loss, train_acc = losses[\"train\"]\n",
    "        val_loss, val_acc = losses[\"val\"]\n",
    "        print(f\"step {step}: train loss {train_loss:.3f}, acc {train_acc:.3f} | val loss {val_loss:.3f}, acc {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d573e7f-7d11-482a-9b42-e02b4fb45ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPOSER_mozart TICKS_PER_BEAT_480 TIME_SIGNATURE_4/4 KEY_D TEMPO_BPM_36 TEMPO_BPM_37 TEMPO_BPM_38 POS_0 NOTE71_ON POS_0 NOTE66_ON POS_0.042 NOTE71_OFF TEMPO_BPM_37 POS_0.5 NOTE74_ON POS_0.525 NOTE66_OFF TEMPO_BPM_35 POS_0.933 NOTE74_OFF TEMPO_BPM_36 TEMPO_BPM_36 POS_0 NOTE74_ON NOTE68_ON NOTE59_ON NOTE53_ON POS_0 NOTE73_ON NOTE61_ON POS_0.025 NOTE74_OFF TEMPO_BPM_37 POS_0.033 NOTE59_OFF POS_0.5 NOTE71_ON NOTE62_ON POS_0.525 NOTE73_OFF NOTE61_OFF POS_0.925 NOTE68_OFF POS_0.933 NOTE71_OFF NOTE62_OFF POS_0.983 NOTE53_OFF TEMPO_BPM_36 POS_0 NOTE73_ON NOTE66_ON NOTE58_ON NOTE54_ON POS_0.217 NOTE54_OFF NOTE66_OFF NOTE58_OFF POS_0.25 NOTE66_ON NOTE58_ON POS_0.467 NOTE58_OFF NOTE66_OFF TEMPO_BPM_36 POS_0.5 NOTE66_ON NOTE58_ON NOTE54_ON POS_0.717 NOTE54_OFF NOTE66_OFF NOTE58_OFF POS_0.75 NOTE65_ON NOTE58_ON TEMPO_BPM_36 POS_0.967 NOTE58_OFF NOTE65_OFF POS_0 NOTE65_ON NOTE58_ON NOTE54_ON POS_0.217 NOTE54_OFF NOTE65_OFF NOTE58_OFF POS_0.25 NOTE65_ON NOTE58_ON NOTE54_ON POS_0.467 NOTE54_OFF NOTE65_OFF NOTE58_OFF POS_0.5 NOTE53_ON NOTE58_ON POS_0.717 NOTE53_OFF NOTE58_OFF POS_0.75 NOTE58_ON NOTE54_ON POS_0.967 NOTE54_OFF NOTE58_OFF POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE54_OFF NOTE59_OFF TEMPO_BPM_37 POS_0.25 NOTE58_ON NOTE54_ON POS_0.475 NOTE54_OFF NOTE59_OFF POS_0.5 NOTE53_ON NOTE59_ON POS_0.717 NOTE53_OFF NOTE59_OFF POS_0.75 NOTE49_ON NOTE54_ON POS_0.967 NOTE54_OFF NOTE49_OFF POS_0 NOTE50_ON NOTE54_ON POS_0.217 NOTE54_OFF NOTE50_OFF POS_0.25 NOTE53_ON POS_0.467 NOTE53_OFF POS_0.5 NOTE54_ON NOTE58_ON POS_0.717 NOTE54_OFF NOTE58_OFF POS_0.75 NOTE53_ON NOTE59_ON TEMPO_BPM_36 POS_0.967 NOTE53_OFF NOTE59_OFF POS_0 NOTE56_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE56_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.433 NOTE68_OFF POS_0.467 NOTE59_OFF NOTE54_OFF POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE53_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE53_OFF POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE54_OFF TEMPO_BPM_38 POS_0.25 NOTE54_ON NOTE59_ON POS_0.467 NOTE59_OFF NOTE54_OFF POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE54_OFF POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.467 NOTE59_OFF NOTE54_OFF POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF TEMPO_BPM_37 POS_0.75 NOTE54_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE54_OFF POS_0 NOTE54_ON NOTE59_ON POS_0.233 NOTE59_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.333 NOTE78_ON POS_0.375 NOTE78_OFF POS_0.467 NOTE59_OFF NOTE54_OFF POS_0.5 NOTE57_ON NOTE78_ON POS_0.625 NOTE78_OFF POS_0.717 NOTE57_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.983 NOTE59_OFF NOTE54_OFF POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.483 NOTE59_OFF NOTE54_OFF POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.992 NOTE59_OFF NOTE54_OFF POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.467 NOTE59_OFF NOTE54_OFF POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE54_OFF TEMPO_BPM_35 POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.467 NOTE59_OFF NOTE54_OFF TEMPO_BPM_37 POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE54_OFF TEMPO_BPM_36 POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.467 NOTE59_OFF NOTE54_OFF TEMPO_BPM_37 POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE54_OFF TEMPO_BPM_36 POS_0 NOTE54_ON NOTE59_ON POS_0.017 NOTE59_OFF NOTE54_OFF TEMPO_BPM_37 POS_0.25 NOTE54_ON NOTE59_ON POS_0.433 NOTE71_OFF POS_0.467 NOTE59_OFF NOTE54_OFF TEMPO_BPM_37 POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE52_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE52_OFF POS_0 NOTE54_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE59_ON TEMPO_BPM_36 POS_0.467 NOTE59_OFF NOTE54_OFF POS_0.5 NOTE54_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE54_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.944 NOTE72_OFF POS_0.967 NOTE59_OFF NOTE54_OFF POS_0 NOTE50_ON NOTE50_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE50_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.433 NOTE71_OFF POS_0.467 NOTE59_OFF NOTE54_OFF TEMPO_BPM_36 POS_0.5 NOTE76_ON NOTE55_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE55_OFF TEMPO_BPM_37 POS_0.75 NOTE54_ON NOTE59_ON POS_0.967 NOTE59_OFF NOTE54_OFF POS_0 NOTE55_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE55_OFF POS_0.25 NOTE54_ON NOTE59_ON POS_0.467 NOTE59_OFF NOTE54_OFF TEMPO_BPM_37 POS_0.5 NOTE74_ON NOTE55_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE55_OFF POS_0.75 NOTE54_ON NOTE59_ON POS_0.892 NOTE74_OFF POS_0.925 NOTE59_OFF NOTE55_OFF POS_0 NOTE75_ON NOTE48_ON POS_0.125 NOTE76_ON POS_0.133 NOTE75_OFF POS_0.25 NOTE75_ON NOTE54_ON NOTE60_ON POS_0.317 NOTE75_OFF NOTE54_OFF NOTE48_OFF POS_0.375 NOTE76_ON POS_0.396 NOTE76_OFF POS_0.408 NOTE60_OFF NOTE54_OFF POS_0.5 NOTE78_ON NOTE52_ON NOTE64_ON POS_0.617 NOTE78_OFF NOTE79_ON POS_0.667 NOTE79_OFF POS_0.717 NOTE64_OFF NOTE52_OFF POS_0.75 NOTE81_ON NOTE54_ON NOTE60_ON POS_0.867 NOTE81_OFF POS_0.875 NOTE83_ON POS_0.917 NOTE60_OFF NOTE54_OFF POS_0 NOTE83_OFF NOTE81_ON NOTE48_ON NOTE60_ON NOTE43_OFF POS_0.158 NOTE81_OFF POS_0.5 NOTE84_ON NOTE52_ON NOTE40_ON POS_0.617 NOTE84_OFF POS_0.625 NOTE83_ON POS_0.667 NOTE40_OFF POS_0.733 NOTE83_OFF POS_0.75 NOTE84_ON NOTE63_ON POS_0.867 NOTE84_OFF POS_0.875 NOTE83_ON POS_0.917 NOTE63_OFF NOTE52_OFF POS_0.942 NOTE40_OFF POS_0.967 NOTE83_OFF POS_0 NOTE84_ON NOTE63_ON NOTE51_ON NOTE39_ON POS_0.117 NOTE84_OFF POS_0.25 NOTE78_ON POS_0.333 NOTE78_OFF POS_0.375 NOTE83_ON POS_0.392 NOTE63_OFF NOTE51_OFF NOTE39_OFF POS_0.467 NOTE83_OFF POS_0.5 NOTE84_ON NOTE63_ON NOTE51_ON NOTE39_ON POS_0.617 NOTE84_OFF POS_0.625 NOTE83_ON POS_0.658 NOTE83_OFF POS_0.75 NOTE84_ON POS_0.867 NOTE84_OFF POS_0.875 NOTE83_ON POS_0.917 NOTE63_OFF NOTE51_OFF NOTE39_OFF POS_0.95 NOTE71_OFF POS_0.975 NOTE83_OFF POS_0 NOTE84_ON NOTE63_ON NOTE51_ON NOTE36_ON POS_0.117 NOTE84_OFF POS_0.125 NOTE83_ON POS_0.15 NOTE63_OFF NOTE51_OFF NOTE39_OFF POS_0.183 NOTE51_OFF POS_0.25 NOTE82_ON NOTE57_ON NOTE52_ON NOTE33_ON POS_0.367 NOTE83_OFF POS_0.375 NOTE83_ON POS_0.417 NOTE57_OFF NOTE52_OFF NOTE33_OFF POS_0.458 NOTE83_OFF POS_0.5 NOTE84_ON NOTE63_ON NOTE51_ON NOTE39_ON POS_0.583 NOTE84_OFF POS_0.625 NOTE82_ON POS_0.642 NOTE63_OFF NOTE51_OFF NOTE39_OFF POS_0.725 NOTE39_OFF POS_0.75 NOTE84_ON NOTE63_ON NOTE51_ON NOTE36_ON NOTE54_ON NOTE37_OFF NOTE38_ON POS_0.842 NOTE84_OFF POS_0.875 NOTE83_ON POS_0.883 NOTE63_OFF NOTE51_OFF NOTE36_OFF POS_0.908 NOTE54_OFF POS_0.942 NOTE82_OFF POS_0 NOTE84_ON NOTE63_ON NOTE51_ON NOTE39_ON POS_0.092 NOTE84_OFF POS_0.125 NOTE82_ON NOTE39_OFF POS_0.175 NOTE63_OFF NOTE51_OFF POS_0.225 NOTE51_OFF POS_0.25 NOTE84_ON NOTE63_ON NOTE51_ON NOTE39_ON POS_0.342 NOTE84_OFF POS_0.375 NOTE83_ON POS_0.408 NOTE63_OFF NOTE51_OFF NOTE39_OFF POS_0.442 NOTE83_OFF POS_0.5 NOTE84_ON NOTE63_ON NOTE51_ON NOTE39_ON POS_0.6 NOTE84_OFF POS_0.625 NOTE83_ON NOTE39_OFF POS_0.658 NOTE63_OFF NOTE51_OFF NOTE39_OFF POS_0.75 NOTE84_ON NOTE63_ON NOTE51_ON NOTE39_ON POS_0.833 NOTE84_OFF POS_0.867 NOTE83_OFF POS_0.875 NOTE80_ON POS_0.883 NOTE63_OFF NOTE51_OFF NOTE39_OFF POS_0.908 NOTE80_OFF POS_0 NOTE82_ON NOTE62_ON NOTE77_ON NOTE51_ON NOTE39_ON POS_0.083 NOTE82_OFF POS_0.125 NOTE81_ON NOTE77_OFF NOTE84_ON POS_0.208 NOTE81_OFF POS_0.242 NOTE60_OFF NOTE51_OFF NOTE39_OFF POS_0.25 NOTE82_ON NOTE84_OFF NOTE82_ON NOTE56_ON NOTE51_ON NOTE39_ON POS_0.367 NOTE82_OFF POS_0.375 NOTE81_ON POS_0.408 NOTE56_OFF NOTE51_OFF NOTE39_OFF POS_0.5 NOTE82_ON NOTE81_OFF NOTE80_ON NOTE53_ON NOTE50_ON NOTE38_ON POS_0.617 NOTE82_OFF POS_0.625 NOTE81_ON NOTE80_OFF NOTE81_ON POS_0.658 NOTE54_OFF NOTE50_OFF NOTE38_OFF POS_0.75 NOTE82_ON NOTE81_OFF NOTE79_ON NOTE56_ON NOTE51_ON NOTE39_ON POS_0.85 NOTE79_OFF POS_0.875 NOTE81_ON POS_0.892 NOTE82_OFF NOTE51_OFF NOTE39_OFF POS_0.958 NOTE51_OFF NOTE39_OFF POS_0.975 NOTE81_OFF POS_0 NOTE80_ON NOTE58_OFF NOTE62_ON NOTE56_ON NOTE50_ON NOTE38_ON POS_0.075 NOTE82_OFF POS_0.125 NOTE81_ON NOTE80_OFF NOTE77_ON POS_0.15 NOTE57_OFF NOTE50_OFF NOTE38_OFF POS_0.25 NOTE82_ON NOTE77_OFF NOTE79_ON POS_0.375 NOTE82_OFF NOTE80_ON NOTE79_OFF NOTE77_ON POS_0.475 NOTE80_OFF POS_0.5 NOTE74_OFF NOTE75_ON NOTE77_OFF NOTE70_ON NOTE65_ON NOTE58_ON NOTE46_ON NOTE34_ON POS_0.6 NOTE70_OFF POS_0.625 NOTE70_ON NOTE76_OFF NOTE74_ON POS_0.7 NOTE70_OFF POS_0.708 NOTE74_OFF POS_0.75 NOTE72_ON NOTE75_ON POS_0.867 NOTE75_OFF POS_0.875 NOTE74_ON NOTE72_OFF\n"
     ]
    }
   ],
   "source": [
    "SOS_ID = stoi[SEQ_SOS]\n",
    "EOS_ID = stoi[SEQ_EOS]\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(start_tokens=None, max_new_tokens=200):\n",
    "    model.eval()\n",
    "    if start_tokens is None:\n",
    "        x = torch.tensor([[SOS_ID]], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        x = torch.tensor([start_tokens], dtype=torch.long, device=device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        x_cond = x[:, -block_size:]\n",
    "        logits = model(x_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # sample\n",
    "        x = torch.cat([x, next_id], dim=1)\n",
    "\n",
    "        # stop at EOS\n",
    "        if int(next_id[0, 0]) == EOS_ID:\n",
    "            break\n",
    "\n",
    "    return x[0].tolist()\n",
    "\n",
    "# Seed with first few tokens from a real piece\n",
    "seed_tokens = encode(mozart_texts[0])[:50]\n",
    "generated_ids = generate(seed_tokens, max_new_tokens=800)\n",
    "generated_text = decode(generated_ids)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "47c0fc5f-aade-4c04-8dc5-0988bea6f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi_conversion import text_to_midi\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "importlib.reload(midi_conversion)\n",
    "\n",
    "mid = text_to_midi(generated_text)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "\n",
    "# Save to path\n",
    "output_path = os.path.join(\"generated\", \"mozart_output.mid\")\n",
    "mid.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2e37fc1-e57e-4f97-aa96-ab1ef3dd1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING TO SEE IF TEXT_TO_MIDI WORKS\n",
    "\n",
    "test_text = \"TICKS_PER_BEAT_480 TIME_SIGNATURE_4/4 KEY_D POS_0 NOTE71_ON POS_0 NOTE66_ON POS_0.042 NOTE71_OFF POS_0.5 NOTE74_ON POS_0.525 NOTE66_OFF POS_0.933 NOTE74_OFF POS_0 NOTE74_ON NOTE68_ON NOTE59_ON NOTE53_ON POS_0 NOTE73_ON NOTE61_ON POS_0.025 NOTE74_OFF POS_0.033 NOTE59_OFF POS_0.5 NOTE71_ON NOTE62_ON POS_0.525 NOTE73_OFF NOTE61_OFF POS_0.925 NOTE68_OFF POS_0.933 NOTE71_OFF NOTE62_OFF POS_0.983 NOTE53_OFF POS_0 NOTE66_ON NOTE71_ON NOTE62_ON NOTE54_ON POS_0.875 NOTE71_OFF NOTE66_OFF POS_0.967 NOTE62_OFF POS_0 NOTE70_ON NOTE61_ON POS_0.375 NOTE76_ON POS_0.396 NOTE70_OFF POS_0.483 NOTE76_OFF NOTE54_OFF POS_0.492 NOTE61_OFF POS_0.5 NOTE73_ON NOTE67_ON NOTE64_ON POS_0.875 NOTE70_ON POS_0.9 NOTE73_OFF POS_0.958 NOTE64_OFF POS_0.975 NOTE67_OFF POS_0.983 NOTE70_OFF POS_0 NOTE73_ON NOTE66_ON NOTE62_ON POS_0.25 NOTE71_ON POS_0.275 NOTE73_OFF POS_0.442 NOTE71_OFF POS_0.45 NOTE66_OFF POS_0.458 NOTE62_OFF POS_0.5 NOTE74_ON NOTE66_ON NOTE58_ON POS_0.75 NOTE73_ON POS_0.775 NOTE74_OFF POS_0.944 NOTE73_OFF POS_0.958 NOTE58_OFF POS_0.967 NOTE66_OFF POS_0 NOTE76_ON NOTE66_ON NOTE59_ON POS_0.25 NOTE74_ON POS_0.279 NOTE76_OFF POS_0.433 NOTE59_OFF NOTE66_OFF POS_0.44 NOTE74_OFF POS_0 NOTE62_ON NOTE66_ON POS_0.217 NOTE66_OFF NOTE62_OFF POS_0.25 NOTE62_ON NOTE66_ON POS_0.467 NOTE66_OFF NOTE62_OFF POS_0.5 NOTE71_ON NOTE83_ON NOTE62_ON NOTE66_ON POS_0.717 NOTE66_OFF NOTE62_OFF POS_0.75 NOTE62_ON NOTE66_ON POS_0.967 NOTE66_OFF NOTE62_OFF POS_0 NOTE61_ON NOTE64_ON POS_0.217 NOTE64_OFF NOTE61_OFF POS_0.25 NOTE61_ON NOTE64_ON POS_0.467 NOTE64_OFF NOTE61_OFF POS_0.5 NOTE70_ON NOTE82_ON NOTE61_ON NOTE64_ON POS_0.544 NOTE71_OFF POS_0.546 NOTE83_OFF POS_0.717 NOTE64_OFF NOTE61_OFF POS_0.75 NOTE61_ON NOTE64_ON POS_0.967 NOTE64_OFF NOTE61_OFF POS_0 NOTE70_OFF NOTE59_ON NOTE62_ON POS_0.008 NOTE82_OFF POS_0.217 NOTE62_OFF NOTE59_OFF POS_0.25 NOTE59_ON NOTE62_ON POS_0.467 NOTE62_OFF NOTE59_OFF POS_0.5 NOTE79_ON NOTE59_ON NOTE62_ON POS_0.717 NOTE62_OFF NOTE59_OFF POS_0.75 NOTE59_ON NOTE62_ON POS_0.875 NOTE81_ON POS_0.9 NOTE79_OFF POS_0.967 NOTE62_OFF NOTE59_OFF POS_0 NOTE79_ON NOTE58_ON NOTE61_ON POS_0.019 NOTE81_OFF POS_0.217 NOTE61_OFF NOTE58_OFF POS_0.25 NOTE58_ON NOTE61_ON POS_0.467 NOTE61_OFF NOTE58_OFF POS_0.5 NOTE78_ON NOTE58_ON NOTE61_ON POS_0.533 NOTE79_OFF POS_0.717 NOTE61_OFF NOTE58_OFF POS_0.75 NOTE58_ON NOTE61_ON POS_0.967 NOTE61_OFF NOTE58_OFF POS_0 NOTE78_OFF NOTE59_ON NOTE62_ON POS_0.217 NOTE62_OFF NOTE59_OFF POS_0.25 NOTE59_ON NOTE62_ON POS_0.467 NOTE62_OFF NOTE59_OFF POS_0.5 NOTE67_ON NOTE79_ON NOTE59_ON NOTE62_ON POS_0.717 NOTE62_OFF NOTE59_OFF POS_0.75 NOTE59_ON NOTE62_ON POS_0.967 NOTE62_OFF NOTE59_OFF POS_0 NOTE57_ON NOTE61_ON POS_0.217 NOTE61_OFF NOTE57_OFF POS_0.25 NOTE57_ON NOTE61_ON POS_0.467 NOTE61_OFF NOTE57_OFF POS_0.5 NOTE66_ON NOTE78_ON NOTE57_ON NOTE61_ON POS_0.544 NOTE79_OFF NOTE67_OFF POS_0.717 NOTE61_OFF NOTE57_OFF POS_0.75 NOTE57_ON NOTE61_ON POS_0.967 NOTE61_OFF NOTE57_OFF POS_0 NOTE66_OFF NOTE78_OFF NOTE55_ON NOTE59_ON POS_0.217 NOTE59_OFF NOTE55_OFF POS_0.25 NOTE55_ON NOTE59_ON POS_0.467 NOTE59_OFF NOTE55_OFF POS_0.5 NOTE76_ON NOTE55_ON NOTE59_ON POS_0.717 NOTE59_OFF NOTE55_OFF POS_0.75 NOTE55_ON NOTE59_ON POS_0.875 NOTE78_ON POS_0.9 NOTE76_OFF POS_0.967 NOTE59_OFF NOTE55_OFF POS_0 NOTE76_ON NOTE57_ON NOTE54_ON POS_0.025 NOTE78_OFF POS_0.25 NOTE59_ON POS_0.275 NOTE57_OFF POS_0.5 NOTE75_ON NOTE60_ON POS_0.525 NOTE59_OFF POS_0.533 NOTE76_OFF POS_0.75 NOTE59_ON POS_0.773 NOTE60_OFF POS_0.933 NOTE75_OFF POS_0.95 NOTE54_OFF POS_0.967 NOTE59_OFF POS_0 NOTE76_ON NOTE59_ON NOTE55_ON POS_0.25 NOTE83_ON POS_0.273 NOTE76_OFF POS_0.5 NOTE81_ON POS_0.527 NOTE83_OFF POS_0.625 NOTE79_ON POS_0.648 NOTE81_OFF POS_0.75 NOTE78_ON POS_0.773 NOTE79_OFF POS_0.875 NOTE76_ON POS_0.9 NOTE78_OFF POS_0.958 NOTE76_OFF POS_0.975 NOTE55_OFF NOTE59_OFF POS_0 NOTE76_ON NOTE57_ON NOTE54_ON POS_0.25 NOTE59_ON POS_0.283 NOTE57_OFF POS_0.5 NOTE75_ON NOTE60_ON POS_0.533 NOTE76_OFF NOTE59_OFF POS_0.75 NOTE59_ON POS_0.783 NOTE60_OFF POS_0.933 NOTE75_OFF POS_0.95 NOTE54_OFF POS_0.967 NOTE59_OFF POS_0 NOTE76_ON NOTE59_ON NOTE55_ON POS_0.25 NOTE83_ON POS_0.275 NOTE76_OFF POS_0.5 NOTE84_ON POS_0.525 NOTE83_OFF POS_0.625 NOTE83_ON POS_0.644 NOTE84_OFF POS_0.75 NOTE81_ON POS_0.773 NOTE83_OFF POS_0.875 NOTE79_ON POS_0.898 NOTE81_OFF POS_0.942 NOTE55_OFF NOTE59_OFF POS_0.975 NOTE79_OFF POS_0 NOTE78_ON NOTE59_ON NOTE56_ON POS_0.25 NOTE61_ON POS_0.275 NOTE59_OFF POS_0.5 NOTE77_ON NOTE62_ON POS_0.517 NOTE61_OFF POS_0.525 NOTE78_OFF POS_0.75 NOTE61_ON POS_0.775 NOTE62_OFF POS_0.875 NOTE56_OFF POS_0.933 NOTE77_OFF POS_0.967 NOTE61_OFF POS_0 NOTE78_ON NOTE61_ON NOTE58_ON POS_0.375 NOTE73_ON POS_0.381 NOTE78_OFF POS_0.433 NOTE61_OFF POS_0.483 NOTE73_OFF POS_0.5 NOTE73_ON NOTE76_ON NOTE67_ON POS_0.967 NOTE58_OFF POS_0 NOTE66_ON NOTE59_ON POS_0.033 NOTE67_OFF POS_0.5 NOTE71_ON NOTE74_ON NOTE65_ON POS_0.525 NOTE66_OFF POS_0.533 NOTE76_OFF NOTE73_OFF POS_0.933 NOTE71_OFF NOTE74_OFF NOTE65_OFF NOTE59_OFF POS_0 NOTE74_ON NOTE78_ON NOTE66_ON NOTE54_ON POS_0.75 NOTE73_ON NOTE76_ON POS_0.773 NOTE78_OFF POS_0.779 NOTE74_OFF POS_0.875 NOTE71_ON NOTE74_ON POS_0.898 NOTE76_OFF POS_0.9 NOTE73_OFF POS_0 NOTE70_ON NOTE73_ON NOTE54_OFF NOTE66_OFF POS_0.023 NOTE71_OFF POS_0.025 NOTE74_OFF POS_0.375 NOTE70_OFF NOTE73_OFF POS_0 NOTE47_ON POS_0 NOTE42_ON POS_0.033 NOTE47_OFF POS_0.5 NOTE50_ON POS_0.525 NOTE42_OFF POS_0.933 NOTE50_OFF POS_0 NOTE77_ON NOTE68_ON NOTE50_ON POS_0 NOTE76_ON NOTE49_ON POS_0.025 NOTE50_OFF POS_0.033 NOTE77_OFF POS_0.5 NOTE74_ON NOTE47_ON POS_0.525 NOTE49_OFF POS_0.533 NOTE76_OFF POS_0.925 NOTE68_OFF POS_0.933 NOTE74_OFF NOTE47_OFF POS_0 NOTE68_ON NOTE74_ON NOTE45_ON POS_0.25 NOTE69_ON NOTE73_ON POS_0.275 NOTE74_OFF NOTE68_OFF POS_0.433 NOTE45_OFF POS_0.467 NOTE69_OFF NOTE73_OFF POS_0.5 NOTE45_ON POS_0.75 NOTE67_ON NOTE71_ON POS_0.933 NOTE45_OFF POS_0.967 NOTE71_OFF NOTE67_OFF POS_0 NOTE47_ON POS_0.25 NOTE66_ON NOTE69_ON POS_0.433 NOTE47_OFF POS_0.467 NOTE69_OFF NOTE66_OFF POS_0.5 NOTE49_ON POS_0.75 NOTE64_ON NOTE67_ON POS_0.933 NOTE49_OFF POS_0.967 NOTE67_OFF NOTE64_OFF POS_0 NOTE66_ON NOTE69_ON NOTE50_ON POS_0.125 NOTE64_ON NOTE67_ON POS_0.158 NOTE69_OFF NOTE66_OFF POS_0.25 NOTE62_ON NOTE66_ON POS_0.283 NOTE64_OFF NOTE67_OFF POS_0.375 NOTE64_ON NOTE67_ON POS_0.383 NOTE66_OFF POS_0.408 NOTE62_OFF POS_0.433 NOTE50_OFF POS_0.5 NOTE62_ON NOTE66_ON POS_0.525 NOTE67_OFF POS_0.533 NOTE64_OFF POS_0.717 NOTE62_OFF NOTE66_OFF POS_0.75 NOTE62_ON POS_0 NOTE61_ON POS_0.033 NOTE62_OFF POS_0.25 NOTE62_ON POS_0.275 NOTE61_OFF POS_0.5 NOTE57_ON POS_0.525 NOTE62_OFF POS_0.75 NOTE54_ON POS_0.775 NOTE57_OFF POS_0.967 NOTE54_OFF POS_0 NOTE55_ON NOTE58_ON POS_0.217 NOTE58_OFF NOTE55_OFF POS_0.25 NOTE55_ON NOTE58_ON POS_0.467 NOTE58_OFF NOTE55_OFF POS_0.5 NOTE61_ON NOTE73_ON NOTE55_ON NOTE58_ON POS_0.717 NOTE58_OFF NOTE55_OFF POS_0.75 NOTE55_ON NOTE58_ON POS_0.967 NOTE58_OFF NOTE55_OFF POS_0 NOTE54_ON NOTE57_ON POS_0.217 NOTE57_OFF NOTE54_OFF POS_0.25 NOTE54_ON NOTE57_ON POS_0.467 NOTE57_OFF NOTE54_OFF POS_0.5 NOTE62_ON NOTE74_ON NOTE54_ON NOTE57_ON POS_0.525 NOTE73_OFF POS_0.533 NOTE61_OFF POS_0.717 NOTE57_OFF NOTE54_OFF POS_0.75 NOTE54_ON NOTE57_ON POS_0.933 NOTE62_OFF NOTE74_OFF POS_0.967 NOTE57_OFF NOTE54_OFF POS_0 NOTE55_ON NOTE64_ON POS_0.217 NOTE64_OFF NOTE55_OFF POS_0.25 NOTE55_ON NOTE64_ON POS_0.467 NOTE64_OFF NOTE55_OFF POS_0.5 NOTE73_ON NOTE85_ON NOTE55_ON NOTE64_ON POS_0.717 NOTE64_OFF NOTE55_OFF POS_0.75 NOTE55_ON NOTE64_ON POS_0.967 NOTE64_OFF NOTE55_OFF POS_0 NOTE56_ON NOTE65_ON POS_0.217 NOTE65_OFF NOTE56_OFF POS_0.25 NOTE56_ON NOTE65_ON POS_0.458 NOTE85_OFF POS_0.467 NOTE73_OFF NOTE65_OFF NOTE56_OFF POS_0.5 NOTE74_ON NOTE86_ON NOTE56_ON NOTE65_ON POS_0.717 NOTE65_OFF NOTE56_OFF POS_0.75 NOTE83_ON NOTE56_ON NOTE62_ON POS_0.783 NOTE86_OFF POS_0.967 NOTE62_OFF NOTE56_OFF POS_0 NOTE74_OFF NOTE81_ON NOTE57_ON NOTE61_ON POS_0.033 NOTE83_OFF POS_0.217 NOTE61_OFF NOTE57_OFF POS_0.25 NOTE57_ON NOTE61_ON POS_0.467 NOTE61_OFF NOTE57_OFF POS_0.5 NOTE80_ON NOTE59_ON NOTE62_ON POS_0.533 NOTE81_OFF POS_0.717 NOTE62_OFF NOTE59_OFF POS_0.75 NOTE59_ON NOTE62_ON POS_0.933 NOTE80_OFF POS_0.967 NOTE62_OFF NOTE59_OFF POS_0 NOTE79_ON NOTE61_ON NOTE64_ON POS_0.217 NOTE64_OFF NOTE61_OFF POS_0.25 NOTE61_ON NOTE64_ON POS_0.467 NOTE64_OFF NOTE61_OFF POS_0.5 NOTE78_ON NOTE62_ON NOTE69_ON POS_0.533 NOTE79_OFF POS_0.625 NOTE79_ON POS_0.652 NOTE78_OFF POS_0.717 NOTE69_OFF NOTE62_OFF POS_0.75 NOTE80_ON NOTE62_ON NOTE66_ON POS_0.771 NOTE79_OFF POS_0.875 NOTE81_ON POS_0.9 NOTE80_OFF POS_0.967 NOTE66_OFF NOTE62_OFF POS_0.975 NOTE81_OFF POS_0 NOTE81_ON NOTE66_ON NOTE57_ON POS_0.65 NOTE66_OFF POS_0.75 NOTE78_ON NOTE62_ON POS_0.775 NOTE81_OFF POS_0.875 NOTE57_OFF POS_0.95 NOTE78_OFF POS_0.967 NOTE62_OFF POS_0 NOTE76_ON NOTE61_ON NOTE57_ON POS_0.396 NOTE76_OFF POS_0.433 NOTE57_OFF NOTE61_OFF POS_0 NOTE66_ON NOTE69_ON NOTE38_ON POS_0.217 NOTE69_OFF NOTE66_OFF POS_0.25 NOTE66_ON NOTE69_ON POS_0.467 NOTE69_OFF NOTE66_OFF POS_0.5 NOTE66_ON NOTE69_ON POS_0.717 NOTE69_OFF NOTE66_OFF POS_0.75 NOTE66_ON NOTE69_ON POS_0.875 NOTE42_ON POS_0.908 NOTE38_OFF POS_0.933 NOTE45_ON POS_0.963 NOTE42_OFF POS_0.967 NOTE69_OFF NOTE66_OFF POS_0 NOTE66_ON NOTE69_ON NOTE50_ON POS_0.033 NOTE45_OFF POS_0.217 NOTE69_OFF NOTE66_OFF POS_0.25 NOTE66_ON NOTE69_ON POS_0.467 NOTE69_OFF NOTE66_OFF POS_0.496 NOTE50_OFF POS_0.5 NOTE66_ON NOTE69_ON POS_0.717 NOTE69_OFF NOTE66_OFF POS_0.75 NOTE66_ON NOTE69_ON POS_0.967 NOTE69_OFF NOTE66_OFF\"\n",
    "\n",
    "mid = text_to_midi(test_text)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "\n",
    "# Save to path\n",
    "output_path = os.path.join(\"generated\", \"mozart_test_output.mid\")\n",
    "mid.save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (musicgen venv)",
   "language": "python",
   "name": "musicgen-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
