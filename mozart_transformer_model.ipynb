{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b5b947-7907-4c08-b8ce-ae09470e3e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading MIDIs from data\\train.\n",
      "Could not load data\\train\\mozart-piano_sonatas-nueva_carpeta-k281_piano_sonata_n03_3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Could not load data\\train\\unknown_artist-i_o-mozart_k550.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 231 MIDI files from data\\train\n",
      "Now loading MIDIs from data\\val.\n",
      "Loaded 20 MIDI files from data\\val\n",
      "Now loading MIDIs from data\\test.\n",
      "Could not load data\\test\\unknown_artist-i_o-mozart_q1_2.mid: MThd not found. Probably not a MIDI file\n",
      "Loaded 22 MIDI files from data\\test\n",
      "273 MIDI files retrieved.\n",
      "Successfully processed 231 MIDIs into text.\n",
      "Successfully processed 20 MIDIs into text.\n",
      "Successfully processed 22 MIDIs into text.\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_midis_by_composer, process_midis_to_text\n",
    "\n",
    "composer = \"mozart\"\n",
    "mozart_midis = get_midis_by_composer(composer)\n",
    "\n",
    "# [[train texts], [val texts], [test texts]]\n",
    "mozart_texts = [[],[],[]]\n",
    "\n",
    "for i, text_list in enumerate(mozart_midis):\n",
    "    text_list = process_midis_to_text(mozart_midis[i], composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416325c-81f3-4d43-ad0c-106768c5ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 606\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# tokenize\n",
    "all_tokens = []\n",
    "for s in seqs:\n",
    "    all_tokens.extend(s.split())\n",
    "\n",
    "vocab = sorted(set(all_tokens))\n",
    "stoi = {t:i for i, t in enumerate(vocab)}\n",
    "itos = {i:t for t,i in stoi.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "def encode(text: str):\n",
    "    return [stoi[t] for t in text.split()]\n",
    "\n",
    "def decode(ids):\n",
    "    return \" \".join(itos[int(i)] for i in ids)\n",
    "\n",
    "# concatenate all pieces into one long stream\n",
    "ids = torch.tensor([stoi[t] for t in all_tokens], dtype=torch.long)\n",
    "\n",
    "# train/val split\n",
    "n = int(0.9 * len(ids))\n",
    "train_data = ids[:n]\n",
    "val_data   = ids[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2c01f-a4f5-4bad-8594-98c4468a5ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from models import MozartTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = MozartTransformer(vocab_size, device=device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23a8cb-4a61-409f-b3e7-67f38d00b08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 6.206, acc 0.030 | val loss 6.144, acc 0.049\n",
      "step 250: train loss 2.197, acc 0.432 | val loss 2.022, acc 0.485\n",
      "step 500: train loss 1.775, acc 0.517 | val loss 1.613, acc 0.562\n",
      "step 750: train loss 1.667, acc 0.538 | val loss 1.501, acc 0.577\n",
      "step 1000: train loss 1.557, acc 0.568 | val loss 1.396, acc 0.599\n",
      "step 1250: train loss 1.465, acc 0.587 | val loss 1.326, acc 0.620\n",
      "step 1500: train loss 1.426, acc 0.595 | val loss 1.287, acc 0.633\n",
      "step 1750: train loss 1.412, acc 0.597 | val loss 1.263, acc 0.635\n",
      "step 2000: train loss 1.373, acc 0.605 | val loss 1.299, acc 0.621\n",
      "step 2250: train loss 1.352, acc 0.608 | val loss 1.229, acc 0.641\n",
      "step 2500: train loss 1.354, acc 0.611 | val loss 1.219, acc 0.644\n",
      "step 2750: train loss 1.294, acc 0.623 | val loss 1.194, acc 0.655\n",
      "step 3000: train loss 1.344, acc 0.617 | val loss 1.223, acc 0.647\n",
      "step 3250: train loss 1.332, acc 0.618 | val loss 1.189, acc 0.654\n",
      "step 3500: train loss 1.268, acc 0.633 | val loss 1.165, acc 0.659\n",
      "step 3750: train loss 1.243, acc 0.642 | val loss 1.167, acc 0.658\n",
      "step 4000: train loss 1.248, acc 0.640 | val loss 1.159, acc 0.666\n",
      "step 4250: train loss 1.198, acc 0.653 | val loss 1.156, acc 0.663\n",
      "step 4500: train loss 1.242, acc 0.641 | val loss 1.174, acc 0.657\n",
      "step 4750: train loss 1.204, acc 0.651 | val loss 1.146, acc 0.667\n",
      "step 5000: train loss 1.181, acc 0.657 | val loss 1.117, acc 0.674\n",
      "step 5250: train loss 1.169, acc 0.660 | val loss 1.135, acc 0.671\n",
      "step 5500: train loss 1.185, acc 0.658 | val loss 1.123, acc 0.673\n",
      "step 5750: train loss 1.245, acc 0.644 | val loss 1.119, acc 0.678\n"
     ]
    }
   ],
   "source": [
    "from model_helpers import get_batch, estimate_loss\n",
    "\n",
    "max_iters = 6000\n",
    "eval_interval = 250\n",
    "\n",
    "for step in range(max_iters):\n",
    "    xb, yb = get_batch(train_data, device=device)\n",
    "    logits = model(xb)\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, vocab_size),\n",
    "        yb.view(-1)\n",
    "    )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        losses = estimate_loss(model, vocab_size, device=device)\n",
    "        train_loss, train_acc = losses[\"train\"]\n",
    "        val_loss, val_acc = losses[\"val\"]\n",
    "        print(f\"step {step}: train loss {train_loss:.3f}, acc {train_acc:.3f} | val loss {val_loss:.3f}, acc {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d573e7f-7d11-482a-9b42-e02b4fb45ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 200 chars of generated text:\n",
      "\n",
      "COMPOSER_mozart KEY_D TIME_SIGNATURE_4/4 TEMPO_BPM_36 MEASURE BEAT POS_0 NOTE_71 DUR_50 VEL_4 BEAT POS_0 NOTE_66 DUR_25 VEL_4 POS_24 NOTE_74 DUR_21 VEL_4 BEAT POS_0 NOTE_53 DUR_95 VEL_6 NOTE_59 DUR_50\n"
     ]
    }
   ],
   "source": [
    "SOS_ID = stoi[SEQ_SOS]\n",
    "EOS_ID = stoi[SEQ_EOS]\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(start_tokens=None, max_new_tokens=200):\n",
    "    model.eval()\n",
    "    if start_tokens is None:\n",
    "        x = torch.tensor([[SOS_ID]], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        x = torch.tensor([start_tokens], dtype=torch.long, device=device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        x_cond = x[:, -block_size:]\n",
    "        logits = model(x_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # sample\n",
    "        x = torch.cat([x, next_id], dim=1)\n",
    "\n",
    "        # stop at EOS\n",
    "        if int(next_id[0, 0]) == EOS_ID:\n",
    "            break\n",
    "\n",
    "    return x[0].tolist()\n",
    "\n",
    "# Seed with first few tokens from a real piece\n",
    "seed_tokens = encode(mozart_texts[0])[:50]\n",
    "generated_ids = generate(seed_tokens, max_new_tokens=800)\n",
    "generated_text = decode(generated_ids)\n",
    "print('First 200 chars of generated text:\\n')\n",
    "print(generated_text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47c0fc5f-aade-4c04-8dc5-0988bea6f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi_conversion import text_to_midi\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "importlib.reload(midi_conversion)\n",
    "\n",
    "mid = text_to_midi(generated_text)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "\n",
    "# Save to path\n",
    "output_path = os.path.join(\"generated\", \"mozart_output.mid\")\n",
    "mid.save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
